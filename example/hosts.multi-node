# 'etcd' cluster should have odd member(s) (1,3,5,...)
[etcd]
192.168.1.1
192.168.1.2
192.168.1.3

# master node(s)
[kube_master]
192.168.1.1
192.168.1.2

# work node(s)
[kube_node]
192.168.1.3
192.168.1.4

# mysql cluster node
# 'MASTER_NODE': 'true' to install a master server;
[mysql_cluster]
192.168.1.1 hostname=mysql-host1 MASTER_DB=true
192.168.1.2 hostname=mysql-host2 MASTER_DB=false
192.168.1.3 hostname=mysql-host3 MASTER_DB=false

[redis_cluster]
192.168.1.1 MASTER_NODE=true
192.168.1.2 MASTER_NODE=false
192.168.1.3 MASTER_NODE=false

[minio_cluster]
192.168.1.1
192.168.1.2
192.168.1.3
192.168.1.4

[nacos_cluster]
192.168.1.1
192.168.1.2
192.168.1.3

[mongo_cluster_master]
192.168.1.1 MASTER_NODE=true
192.168.1.2 MASTER_NODE=false
192.168.1.3 MASTER_NODE=false

[mongo_cluster_shard:children]
mongo_shard1
mongo_shard2

# SHARD_NAME 必须与 group name 保值一致，否则无法对不同的 shard 分别初始化 repliset
[mongo_shard1]
192.168.1.1 SHARD_NAME=mongo_shard1 MASTER_NODE=true
192.168.1.2 SHARD_NAME=mongo_shard1 MASTER_NODE=false
192.168.1.3 SHARD_NAME=mongo_shard1 MASTER_NODE=false

[mongo_shard2]
192.168.1.4 SHARD_NAME=mongo_shard2 MASTER_NODE=true
192.168.1.5 SHARD_NAME=mongo_shard2 MASTER_NODE=false
192.168.1.6 SHARD_NAME=mongo_shard2 MASTER_NODE=false

[rabbitmq_cluster]
192.168.1.1 hostname=rabbitmq-host1 MASTER_QUEUE=true
192.168.1.2 hostname=rabbitmq-host2 MASTER_QUEUE=false
192.168.1.3 hostname=rabbitmq-host3 MASTER_QUEUE=false

# [optional] harbor server, a private docker registry
# 'NEW_INSTALL': 'true' to install a harbor server; 'false' to integrate with existed one
[harbor]
#192.168.1.8 NEW_INSTALL=false

# [optional] loadbalance for accessing k8s from outside
[ex_lb]
#192.168.1.6 LB_ROLE=master EX_APISERVER_VIP=192.168.1.250 EX_APISERVER_PORT=8443
#192.168.1.7 LB_ROLE=backup EX_APISERVER_VIP=192.168.1.250 EX_APISERVER_PORT=8443

[nginx_node]
#192.168.1.6 NGINX_ROLE=master EX_NGINX_VIP=192.168.1.251
#192.168.1.7 NGINX_ROLE=backup EX_NGINX_VIP=192.168.1.251

# [optional] ntp server for the cluster
[chrony]
#192.168.1.1

# zookeeper cluster node
[zookeeper_cluster]
192.168.1.1 myid=1
192.168.1.2 myid=2
192.168.1.3 myid=3

# kafka cluster node
[kafka_cluster]
192.168.1.1 broker_id=1
192.168.1.2 broker_id=2
192.168.1.3 broker_id=3

# elasticsearch cluster node
[es_cluster]
192.168.1.1 node_name=node-1
192.168.1.2 node_name=node-2
192.168.1.3 node_name=node-3

# elasticsearch6 cluster node
[es6_cluster]
192.168.1.1 node_name=node-1
192.168.1.2 node_name=node-2
192.168.1.3 node_name=node-3

# influx node
[influx_cluster]
192.168.1.1

# skywalking cluster node
[skywalking_cluster]
192.168.1.1
192.168.1.2
192.168.1.3

[telegraf_nodes]
192.168.1.1
192.168.1.2
192.168.1.3

[filebeat_nodes:children]
telegraf_nodes

[all:vars]
# --------- Main Variables ---------------
# Secure port for apiservers
SECURE_PORT="6443"

# Cluster container-runtime supported: docker, containerd
CONTAINER_RUNTIME="containerd"

# Network plugins supported: calico, flannel, kube-router, cilium, kube-ovn
CLUSTER_NETWORK="calico"

# Service proxy mode of kube-proxy: 'iptables' or 'ipvs'
PROXY_MODE="ipvs"

# K8S Service CIDR, not overlap with node(host) networking
SERVICE_CIDR="10.68.0.0/16"

# Cluster CIDR (Pod CIDR), not overlap with node(host) networking
CLUSTER_CIDR="172.20.0.0/16"

# NodePort Range
NODE_PORT_RANGE="30000-32767"

# Cluster DNS Domain
CLUSTER_DNS_DOMAIN="cluster.local"

# -------- Additional Variables (don't change the default value right now) ---
# Binaries Directory
bin_dir="/opt/kube/bin"

# Deploy Directory (kubeasz workspace)
base_dir="/etc/kubeasz"

# Directory for a specific cluster
cluster_dir="{{ base_dir }}/clusters/_cluster_name_"

# CA and other components cert/key Directory
ca_dir="/etc/kubernetes/ssl"
